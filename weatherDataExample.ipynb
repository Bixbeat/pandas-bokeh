{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandasql import sqldf\n",
    "import folium\n",
    "import bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadWeatherData(fileName):\n",
    "    \n",
    "    weatherHeaderList = []\n",
    "    weatherDict = {}\n",
    "    spatialHeaderList = []\n",
    "    spatialDict = {}\n",
    "    \n",
    "    def clearWhitespace(element, charactersToRemove):\n",
    "        charactersInElement = [character for character in list(element) if character not in charactersToRemove]\n",
    "        cleanedElement = ''.join(charactersInElement)\n",
    "        return cleanedElement\n",
    "    \n",
    "    def cleanHeader(headerLine, headerList, headerDict, separator):\n",
    "        selectedHeaderLine = headerLine\n",
    "        splitHeaderList = selectedHeaderLine.split(separator)\n",
    "        #Determine headers in the main file (operations in order: remove hashtag, append main body, remove trailing line break)\n",
    "        uncleanedHeaderList = [splitHeaderList[0][2:]]\\\n",
    "                            + splitHeaderList[1:-1] \\\n",
    "                            + [splitHeaderList[-1][:-1]]\n",
    "        for element in uncleanedHeaderList:\n",
    "            cleanedHeader = clearWhitespace(element, (' '))\n",
    "            #Ensure that only valid headers are added (empty = not appended)\n",
    "            if len(cleanedHeader) > 0:\n",
    "                headerList.append(cleanedHeader)\n",
    "                headerDict[cleanedHeader] = []\n",
    "    \n",
    "    with open(fileName) as data:\n",
    "        loadedData = data.readlines()\n",
    "        \n",
    "        '''Process weather data header'''\n",
    "        cleanHeader(loadedData[97], weatherHeaderList, weatherDict, ',')     \n",
    "        \n",
    "        '''Process main weather data'''\n",
    "        uncleanedWeatherData = loadedData[100:2000]\n",
    "        weatherData = [line.split(',') for line in uncleanedWeatherData[:]]        \n",
    "        \n",
    "        for lines in weatherData:\n",
    "            for elementNumber, elements in enumerate(lines):\n",
    "                cleanedElement = clearWhitespace(elements,(' ', '\\n'))\n",
    "                #Error handling required to prevent unexpected EOF while parsing - no known alternatives         \n",
    "                try:\n",
    "                    evaluatedValue = eval(cleanedElement)\n",
    "                    weatherDict[weatherHeaderList[elementNumber]].append(evaluatedValue)                    \n",
    "                except:\n",
    "                    weatherDict[weatherHeaderList[elementNumber]].append(cleanedElement)\n",
    "        \n",
    "        '''Process spatail data headers'''   \n",
    "        cleanHeader(loadedData[4], spatialHeaderList, spatialDict, ' ')\n",
    "        \n",
    "        '''Process main spatial data'''\n",
    "        uncleanedSpatialData = loadedData[5:54]\n",
    "        #Splitting spatial data lines\n",
    "        splitSpatialData = [line.split() for line in uncleanedSpatialData[:]]    \n",
    "        spatialData = list(map(lambda values: values[1:], splitSpatialData))\n",
    "        #Remove trailing colon after first element\n",
    "        for lines in spatialData:\n",
    "            lines[0] = lines[0][:-1]\n",
    "            while len(lines) > len(spatialHeaderList):\n",
    "                lines[len(spatialHeaderList)-1] = str(lines[len(spatialHeaderList)-1]) + ' ' + str(lines[len(spatialHeaderList)])\n",
    "                del lines[len(spatialHeaderList)]\n",
    "            for elementNumber, element in enumerate(lines):\n",
    "                try:\n",
    "                    spatialDict[spatialHeaderList[elementNumber]].append(eval(element))\n",
    "                except:\n",
    "                    spatialDict[spatialHeaderList[elementNumber]].append(element)\n",
    "        \n",
    "        '''Combine header files'''\n",
    "        headers = weatherHeaderList[:] + spatialHeaderList[:]\n",
    "            \n",
    "    return weatherDict, spatialDict, headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Loading time is approx 5 minutes for full dataset\n",
    "data = loadWeatherData(r'D:\\git\\pandas-bokeh\\data\\KNMI_20161227.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Joining the two datasets together\n",
    "weatherDF = pd.DataFrame(data[0])[1:].apply(pd.to_numeric)\n",
    "spatialDF = pd.DataFrame(data[1])\n",
    "\n",
    "#Runtime is about 5mins\n",
    "performSQL = lambda q: sqldf(q, globals())\n",
    "\n",
    "sql = \"\"\"\n",
    "        SELECT * FROM weatherDF\n",
    "        JOIN spatialDF ON spatialDF.stn = weatherDF.stn;\n",
    "      \"\"\"\n",
    "\n",
    "weatherAndSpatialDataDF = performSql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['209']\n"
     ]
    }
   ],
   "source": [
    "#Select unique station names\n",
    "sql = \"\"\"\n",
    "        SELECT DISTINCT(STN) FROM weatherAndSpatialDataDF\n",
    "      \"\"\"\n",
    "#List index -1 is to filter a trailing empty record that is returned with this syntax\n",
    "uniqueStationNumbers = performSQL(sql).to_csv(None, header=False, index=False).split('\\n')[:-1]\n",
    "print uniqueStationNumbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['72.209774849']\n"
     ]
    }
   ],
   "source": [
    "#Runtime for an avg selection takes about 5min per marker\n",
    "#Plots graphs into folium markers, then adds markers to map & loads map inline\n",
    "#evening_map = folium.Map(location=[52.092560, 5.109378],zoom_start=13)\n",
    "\n",
    "for number in uniqueStationNumbers:\n",
    "    sql = \"\"\"\n",
    "        SELECT avg(FG) FROM weatherAndSpatialDataDF\n",
    "        WHERE STN = {stationNumber}\n",
    "      \"\"\".format(stationNumber = number)\n",
    "    maxWindSpeedList = performSQL(sql).to_csv(None, header=False, index=False).split('\\n')[:-1]\n",
    "    print maxWindSpeedList\n",
    "    \n",
    "    sql = \"\"\"\n",
    "        SELECT \"LON(east)\", \"LAT(north)\", \"NAME\" FROM weatherAndSpatialDataDF\n",
    "        WHERE STN = {stationNumber}\n",
    "        GROUP BY NAME\n",
    "      \"\"\".format(stationNumber = number)\n",
    "    stationLocationAndName = performSQL(sql).to_csv(None, header=False, index=False).split('\\n')[:-1]\n",
    "    stationLocationAndName = stationLocationAndName[0].split(',')\n",
    "    \n",
    "    #Specify path to load figures from\n",
    "    #url = r\"http://localhost:8888/files/UtrechtTraffic/utrecht/git/plots/{}.png\".format(code)\n",
    "    #graph ='<img src=\"{}\">'.format(url)\n",
    "\n",
    "    #http://gis.stackexchange.com/questions/185897/how-can-i-include-html-in-a-folium-marker-popup\n",
    "    #\n",
    "    #marker.apply(lambda row: folium.Marker([row['latitude'], row['longitude']],\\\n",
    "    #                        popup=folium.Popup(folium.element.IFrame(html=graph,\n",
    "    #                        width=550, height=500),\\\n",
    "    #                        max_width=550))\\\n",
    "    #                        .add_to(evening_map), axis =1) \n",
    "#evening_map.save('evening.html')\n",
    "#evening_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

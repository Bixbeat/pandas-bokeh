{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Standard libraries\n",
    "from datetime import date, timedelta\n",
    "import numpy as np\n",
    "\n",
    "#Non-standard libraries\n",
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "import folium\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.resources import CDN\n",
    "from bokeh.embed import file_html\n",
    "from bokeh.models import DatetimeTickFormatter, HoverTool, BoxSelectTool, WheelZoomTool, PanTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#source: http://projects.knmi.nl/klimatologie/daggegevens/selectie.cgi\n",
    "#Can be loaded directly, no pre-processing is needed\n",
    "file_name = r'D:\\git\\pandas-bokeh\\data\\KNMI_20161227.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell defines the method to load the weather data.<br>\n",
    "Because of pandasql's limitations in terms of data size, one weather point is loaded at a time.\n",
    "Loading the entire dataset took about 5 minutes, with processing times through the roof.\n",
    "Unfortunately this means that there is no cross-point comparison of attributes possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_weather_data(file_name,station_numbers):\n",
    "    \n",
    "    weather_header_list = []\n",
    "    weather_dict = {}\n",
    "    spatial_header_list = []\n",
    "    spatial_dict = {}\n",
    "    \n",
    "    def clear_whitespace(element, characters_to_remove):\n",
    "        characters_in_element = [character for character in list(element) if character not in characters_to_remove]\n",
    "        cleaned_element = ''.join(characters_in_element)\n",
    "        return cleaned_element\n",
    "    \n",
    "    def process_headers(header_line, header_list, header_dict, separator, unique_id = 'False'):\n",
    "        selected_header_line = header_line\n",
    "        split_header_list = selected_header_line.split(separator)\n",
    "        #Determine headers in the main file (operations in order: remove hashtag, append main body, remove trailing line break)\n",
    "        uncleaned_header_list = [split_header_list[0][2:]]\\\n",
    "                            + split_header_list[1:-1] \\\n",
    "                            + [split_header_list[-1][:-1]]\n",
    "                \n",
    "        for element in uncleaned_header_list:\n",
    "            cleaned_header = clear_whitespace(element, (' '))\n",
    "            #Ensure that only valid headers are added (empty = not appended)\n",
    "            if len(cleaned_header) > 0:\n",
    "                header_list.append(cleaned_header)\n",
    "                header_dict[cleaned_header] = []\n",
    "        if unique_id == True:\n",
    "            header_list.append('ID')\n",
    "            header_dict['ID'] = []\n",
    "            \n",
    "    \n",
    "    with open(file_name) as data:\n",
    "        loaded_data = data.readlines()\n",
    "        \n",
    "        '''Process weather data header'''\n",
    "        process_headers(loaded_data[97], weather_header_list, weather_dict, ',', unique_id = True)\n",
    "        \n",
    "        '''Process weather data attributes'''\n",
    "        uncleaned_weather_data = [line for line in loaded_data[100:] if line[2:5] in station_numbers]#stationNumber]\n",
    "        weather_data = [line.split(',') for line in uncleaned_weather_data[:]]        \n",
    "        \n",
    "        for linenumber, lines in enumerate(weather_data):\n",
    "            for element_number, elements in enumerate(lines):\n",
    "                cleaned_element = clear_whitespace(elements,(' ', '\\n'))\n",
    "                #Error handling required to prevent unexpected EOF while parsing - no known alternatives         \n",
    "                try:\n",
    "                    evaluated_value = eval(cleaned_element)\n",
    "                    weather_dict[weather_header_list[element_number]].append(evaluated_value)                    \n",
    "                except:\n",
    "                    weather_dict[weather_header_list[element_number]].append(cleaned_element)\n",
    "            weather_dict['ID'].append(linenumber)\n",
    "        \n",
    "        '''Process spatial data headers'''   \n",
    "        process_headers(loaded_data[4], spatial_header_list, spatial_dict, ' ')\n",
    "        \n",
    "        '''Process spatial data attributes'''\n",
    "        uncleaned_spatial_data = loaded_data[5:55]\n",
    "        #Splitting spatial data lines\n",
    "        split_spatial_data = [line.split() for line in uncleaned_spatial_data[:]]    \n",
    "        spatial_data = list(map(lambda values: values[1:], split_spatial_data))\n",
    "        #Remove trailing colon after first element\n",
    "        for lines in spatial_data:\n",
    "            lines[0] = lines[0][:-1]\n",
    "            while len(lines) > len(spatial_header_list):\n",
    "                lines[len(spatial_header_list)-1] = str(lines[len(spatial_header_list)-1]) + ' ' + str(lines[len(spatial_header_list)])\n",
    "                del lines[len(spatial_header_list)]\n",
    "            for element_number, element in enumerate(lines):\n",
    "                try:\n",
    "                    spatial_dict[spatial_header_list[element_number]].append(eval(element))\n",
    "                except:\n",
    "                    spatial_dict[spatial_header_list[element_number]].append(element)\n",
    "        \n",
    "        '''Combine header lists'''\n",
    "        headers = weather_header_list[:] + spatial_header_list[:]\n",
    "            \n",
    "    return weather_dict, spatial_dict, headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell defines the go-to function to execute SQL using pandasql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perform_SQL = lambda q: sqldf(q, globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the one-at-a-time structure of the script is is necessary to derive all station numbers.\n",
    "The following method accesses the data and retrieves the numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_unique_stations(file_name):\n",
    "    with open(file_name) as data:\n",
    "        loaded_data = data.readlines()\n",
    "        unique_numbers = sorted(list(set(list([line[2:5] for line in loaded_data[100:]]))))\n",
    "    return unique_numbers\n",
    "unique_station_numbers = get_unique_stations(file_name)\n",
    "\n",
    "#Variable for testing. Comment out to loop over the entire set\n",
    "unique_station_numbers = [unique_station_numbers[3],\n",
    "                          unique_station_numbers[15],\n",
    "                          unique_station_numbers[23],\n",
    "                          unique_station_numbers[33],\n",
    "                          unique_station_numbers[44]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell the data is queried, processed, and added to a Folium marker.<br>\n",
    "While it may have been neater to divive blocks into functions, the requirements and parameters are so bespoke that the function call would include too many parameters. Hence, they are displayed as-is and the loop is not subdivided further.<br><br>\n",
    "In order, the following operations are performed in the blocks:<br>\n",
    "\n",
    "1. Retrieve data using load_weather_data function defined earlier <br>\n",
    "2. Query the dataset to derive max wind speed and temp. difference in two days using the pandasql framework <br>\n",
    "3. Plot the temperature difference data using Bokeh <br>\n",
    "4. Add the Bokeh plot to a Folium marker, which is then added to the main map <br>\n",
    "\n",
    "When looping over all station numbers, loading times are very high (in the order of ~30 minutes for a full run).\n",
    "Using a dedicated geodatabase is absolutely preferred to drastically reduce processing times.\n",
    "However, since that would void the premise of using pandasql, it was chosen to leave it as-is.\n",
    "Lastly, the map saves to the location of the script by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Gathers data using SQL queries which is then added to the markers\n",
    "#Map is added separately in the Github repository as the IFrame does not load on Github\n",
    "#500 rows are plotted per testing point. Either remove the slice of weather_DF or check out the Python script in the repository\n",
    "\n",
    "#Initialize weather station map\n",
    "save_map = True\n",
    "weather_stations_map = folium.Map(location=[52.092560, 5.109378],zoom_start = 7)\n",
    "\n",
    "for station_number in unique_station_numbers:\n",
    "    #Get data for unique station numbers\n",
    "    loaded_data = load_weather_data(file_name, station_number)\n",
    "\n",
    "    #Convert data into Pandas Dataframes\n",
    "    weather_DF = pd.DataFrame(loaded_data[0])[1:].apply(pd.to_numeric)[499:999]\n",
    "    spatial_DF = pd.DataFrame(loaded_data[1])    \n",
    "    \n",
    "    #Get weather data by querying newly made dataframes\n",
    "    sql = \"\"\"\n",
    "            SELECT STN, MAX(FHX) FROM weather_DF\n",
    "            WHERE STN = {unique_station_numbers}\n",
    "          \"\"\".format(unique_station_numbers = station_number)\n",
    "    max_wind_speed_list = perform_SQL(sql).to_csv(None, header=False, index=False).split('\\n')[:-1]\n",
    "    max_wind_speed_list = max_wind_speed_list[0].split(',')\n",
    "    try:\n",
    "        max_wind_speed_value = float(max_wind_speed_list[1])/10\n",
    "    except:\n",
    "        max_wind_speed_value = \"no data\"\n",
    "    \n",
    "    #Get temperature difference between two dates for each row in the weather_DF dataframe\n",
    "    sql = \"\"\"\n",
    "            SELECT day1.YYYYMMDD, day1.ID, (day1.TG/10) AS day1temp, (day2.TG/10) AS day2temp, IFNULL(CAST(day1.TG - day2.TG AS float)/10, 0) AS difference\n",
    "            FROM weather_DF AS day1\n",
    "                JOIN weather_DF day2 ON day1.STN = day2.STN AND day2.ID - day1.ID == 1\n",
    "          \"\"\"\n",
    "    tempdif_DF = perform_SQL(sql)\n",
    "    tempdif_DF['YYYYMMDD'] = tempdif_DF['YYYYMMDD'].apply(lambda x: pd.to_datetime(str(x), format='%Y%m%d'))    \n",
    "    biggest_tempdif_value = max(tempdif_DF['difference'])\n",
    "\n",
    "    try:\n",
    "        highest_tempdif_row = tempdif_DF.loc[tempdif_DF['difference'] == biggest_tempdif_value]\n",
    "        highest_tempdif_date = str(highest_tempdif_row.iloc[0][0])\n",
    "\n",
    "    except:\n",
    "        biggest_tempdif_formatted = \"no data\"\n",
    "        highest_tempdif_date = \"no data\"\n",
    "    \n",
    "    #Draw simple plot for temperature data\n",
    "    #Create spectral colour palette column (http://bokeh.pydata.org/en/latest/docs/gallery/elements.html)\n",
    "    differences = tempdif_DF['difference']\n",
    "    palette = [\"#053061\", \"#2166ac\", \"#4393c3\", \"#92c5de\", \"#d1e5f0\",\n",
    "               \"#f7f7f7\", \"#fddbc7\", \"#f4a582\", \"#d6604d\", \"#b2182b\", \"#67001f\"]\n",
    "    lower_bound = min(differences)\n",
    "    upper_bound = max(differences)\n",
    "    if lower_bound != 0 and upper_bound !=0:\n",
    "        diff_colours = [int(10*(value - lower_bound)/(upper_bound - lower_bound)) for value in differences]\n",
    "        tempdif_DF['colours'] = [palette[i] for i in diff_colours]\n",
    "    else:\n",
    "        tempdif_DF['colours'] = palette[0]\n",
    "    \n",
    "    #Configure the hover tool\n",
    "    hover = HoverTool(tooltips=[(\"Temp. difference\", \"@y{2.2}\")])\n",
    "    \n",
    "    #Assign the tools and create the plot\n",
    "    tools = [BoxSelectTool(), WheelZoomTool(), PanTool(), hover]    \n",
    "    temp_dif_graph = figure(title = \"temp. change at station {}\".format(station_number),\\\n",
    "        x_axis_label = 'year', y_axis_label = 'temperature difference', tools = tools)\n",
    "\n",
    "    temp_dif_graph.circle(tempdif_DF['YYYYMMDD'], tempdif_DF['difference'],\\\n",
    "                          legend = \"Temperature difference in 2 days\",\\\n",
    "                          size = 8,\\\n",
    "                          color = tempdif_DF[\"colours\"],\\\n",
    "                          alpha = 1.0)\n",
    "\n",
    "    #Set years to x-axis (http://stackoverflow.com/questions/33869292/how-can-i-set-the-x-axis-as-datetimes-on-a-bokeh-plot)\n",
    "    #Bokeh gets a bit strange with datetime ticks. I had to set months to the year value before it worked with a\n",
    "    #subselection of the dataframe. If you want to analyse the entire dataframe once, comment out the top line and uncomment the bottom one.\n",
    "    \n",
    "    temp_dif_graph.xaxis.formatter=DatetimeTickFormatter(formats=dict(months=[\"%Y\"]))\n",
    "    #temp_dif_graph.xaxis.formatter=DatetimeTickFormatter(formats=dict(years=[\"%Y\"]))\n",
    "    \n",
    "    #Generate HTML for the plot\n",
    "    weather_dif_graph_html = file_html(temp_dif_graph, CDN, \"temp dif plot\")\n",
    "    \n",
    "    #Get spatial data from spatial_DF\n",
    "    sql = \"\"\"\n",
    "            SELECT \"LAT(north)\", \"LON(east)\" FROM spatial_DF\n",
    "            WHERE STN = {unique_station_numbers}\n",
    "          \"\"\".format(unique_station_numbers = station_number)\n",
    "    spatial_data_list = perform_SQL(sql).to_csv(None, header=False, index=False).split('\\n')[:-1]\n",
    "    spatial_data_list = spatial_data_list[0].split(',')\n",
    "\n",
    "    #Create Folium marker and assign to pre-made map\n",
    "    folium.Marker([spatial_data_list[0], spatial_data_list[1]],\\\n",
    "        popup = folium.Popup(folium.element.IFrame(\n",
    "        html='''\n",
    "                <b>Station:</b>            {stn} <br>\n",
    "                <b>Maximum wind speed:</b> {fg} m/s<br>\n",
    "             '''.format(stn = max_wind_speed_list[0],\\\n",
    "                   fg = max_wind_speed_value)\\\n",
    "                   + weather_dif_graph_html,\\\n",
    "        width=700, height=700),\\\n",
    "        max_width=700)).add_to(weather_stations_map)\n",
    "\n",
    "if save_map == True:    \n",
    "    weather_stations_map.save('weather_stations_map.html')\n",
    "weather_stations_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Scratchpad###\n",
    "#Joining the two datasets together - no longer used but kept for reference\n",
    "def join_dataframes(weather_dict, spatial_dict):\n",
    "    weather_DF = pd.DataFrame(weather_dict)[1:].apply(pd.to_numeric)\n",
    "    spatial_DF = pd.DataFrame(spatial_dict)\n",
    "\n",
    "    #Runtime is about 5mins for the full set, it is preferred to not join and handle the entire set at once\n",
    "    sql = \"\"\"\n",
    "            SELECT * FROM weather_DF\n",
    "            JOIN spatial_DF ON spatial_DF.stn = weather_DF.stn;\n",
    "          \"\"\"\n",
    "\n",
    "    weather_and_spatial_data_DF = perform_SQL(sql)\n",
    "    return weather_and_spatial_data_DF\n",
    "\n",
    "#Set years to x-axis (http://stackoverflow.com/questions/33869292/how-can-i-set-the-x-axis-as-datetimes-on-a-bokeh-plot)\n",
    "#Bokeh gets a bit strange with datetime ticks. I had to set months to the year value before it worked. Don't know why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
